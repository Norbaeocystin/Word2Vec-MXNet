{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compiling cython code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling preprocessing.pyx because it changed.\n",
      "[1/1] Cythonizing preprocessing.pyx\n",
      "running build_ext\n",
      "building 'preprocessing' extension\n",
      "creating build\n",
      "creating build/temp.linux-x86_64-2.7\n",
      "x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -Wstrict-prototypes -fno-strict-aliasing -Wdate-time -D_FORTIFY_SOURCE=2 -g -fstack-protector-strong -Wformat -Werror=format-security -fPIC -I/usr/local/lib/python2.7/dist-packages/numpy/core/include -I. -I/usr/include/python2.7 -c preprocessing.c -o build/temp.linux-x86_64-2.7/preprocessing.o\n",
      "In file included from \u001b[01m\u001b[K/usr/local/lib/python2.7/dist-packages/numpy/core/include/numpy/ndarraytypes.h:1809:0\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python2.7/dist-packages/numpy/core/include/numpy/ndarrayobject.h:18\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python2.7/dist-packages/numpy/core/include/numpy/arrayobject.h:4\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[Kpreprocessing.c:444\u001b[m\u001b[K:\n",
      "\u001b[01m\u001b[K/usr/local/lib/python2.7/dist-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:15:2:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K#warning \"Using deprecated NumPy API, disable it by \" \"#defining NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [-Wcpp]\n",
      " #warning \"Using deprecated NumPy API, disable it by \" \\\n",
      "\u001b[01;32m\u001b[K  ^\u001b[m\u001b[K\n",
      "x86_64-linux-gnu-gcc -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -fno-strict-aliasing -DNDEBUG -g -fwrapv -O2 -Wall -Wstrict-prototypes -Wdate-time -D_FORTIFY_SOURCE=2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wl,-Bsymbolic-functions -Wl,-z,relro -Wdate-time -D_FORTIFY_SOURCE=2 -g -fstack-protector-strong -Wformat -Werror=format-security build/temp.linux-x86_64-2.7/preprocessing.o -o /home/ubuntu/phantom/word2vec/Word2Vec-MXNet/cython/preprocessing.so\n"
     ]
    }
   ],
   "source": [
    "!python setup.py build_ext --inplace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import mxnet as mx\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.word2vec import Text8Corpus\n",
    "from preprocessing import data_iterator_cython\n",
    "import logging\n",
    "import sys, random, time, math\n",
    "from collections import namedtuple\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building vocab took 7.36954212189 seconds\n"
     ]
    }
   ],
   "source": [
    "corpus = Text8Corpus(\"text8\")\n",
    "current_time = time.time()\n",
    "model = Word2Vec(iter=1, sg=1)\n",
    "model.build_vocab(corpus)\n",
    "print \"Building vocab took %s seconds\" % (time.time() - current_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_data = []\n",
    "batch_label = []\n",
    "batch_label_weight = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61.8788969517\n",
      "data prep took:  61.8791129589\n"
     ]
    }
   ],
   "source": [
    "current_time = time.time()\n",
    "job_batch, batch_size = [], 0\n",
    "for sent_idx, sentence in enumerate(corpus):\n",
    "    sentence_length = model._raw_word_count([sentence])\n",
    "\n",
    "    # can we fit this sentence into the existing job batch?\n",
    "    if batch_size + sentence_length <= model.batch_words:\n",
    "        # yes => add it to the current job\n",
    "        job_batch.append(sentence)\n",
    "        batch_size += sentence_length\n",
    "    else:\n",
    "        sents = data_iterator_cython(model, job_batch, model.alpha)\n",
    "        for sent in sents:\n",
    "            batch_data.append(sent[0])\n",
    "            batch_label.append(sent[1:])\n",
    "        job_batch[:] = []\n",
    "        batch_size = 0\n",
    "print time.time() - current_time\n",
    "print \"data prep took: \", time.time() - current_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_data = mx.nd.array(batch_data)\n",
    "batch_label = mx.nd.array(batch_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_weight = mx.nd.zeros((batch_data.shape[0], model.negative+1))\n",
    "target_weight[:,0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_data = batch_data.reshape((batch_data.shape[0],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nd_iter = mx.io.NDArrayIter(data = {\"center_word\" : batch_data, \"target_words\": batch_label},\n",
    "                            label={ \"labels\":target_weight},\n",
    "                            batch_size=batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "neg_dim = model.negative\n",
    "vocab = len(model.wv.vocab)\n",
    "dim = model.vector_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_sym_makeloss(vocab_size, dim, batch_size):\n",
    "    labels = mx.sym.Variable('labels') #1 positive and k \"0\" labels\n",
    "    center_word = mx.sym.Variable('center_word')\n",
    "    target_words = mx.sym.Variable('target_words') # 1 target + k negative samples\n",
    "    center_vector = mx.sym.Embedding(data = center_word, input_dim = vocab_size,\n",
    "                                  output_dim = dim, name = 'syn0_embedding')\n",
    "    target_vectors = mx.sym.Embedding(data = target_words, input_dim = vocab_size,\n",
    "                                   output_dim = dim, name = 'syn1_embedding')\n",
    "    pred = mx.sym.broadcast_mul(center_vector, target_vectors)\n",
    "    pred = mx.sym.sum(data = pred, axis = 2)\n",
    "    sigmoid = mx.sym.sigmoid(pred)\n",
    "    loss = mx.sym.sum(labels * mx.sym.log(sigmoid) + (1 - labels) * mx.sym.log(1 - sigmoid), axis=1)\n",
    "    loss *= -1.0 / batch_size \n",
    "    loss_layer = mx.sym.MakeLoss(loss)\n",
    "    return loss_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sym = get_sym_makeloss(vocab, dim, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "network = mx.mod.Module(sym, data_names=(\"center_word\", \"target_words\",), label_names=(\"labels\",),context=mx.gpu())\n",
    "network.bind(data_shapes=nd_iter.provide_data, label_shapes=nd_iter.provide_label)\n",
    "current_time = time.time()\n",
    "network.fit(nd_iter, num_epoch=1,optimizer=mx.optimizer.Adam(learning_rate=0.025),\n",
    "            eval_metric=mx.metric.Torch(),initializer=mx.initializer.Uniform(scale=.01))\n",
    "print time.time() - current_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_vecs = network.get_params()[0][\"syn0_embedding_weight\"].asnumpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.wv.syn0 = all_vecs\n",
    "model.wv.syn0norm = all_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'wind', 1.0105350017547607),\n",
       " (u'calendar', 0.9821910858154297),\n",
       " (u'faster', 0.9229880571365356),\n",
       " (u'leap', 0.9178435802459717),\n",
       " (u'output', 0.9089897871017456),\n",
       " (u'seconds', 0.9083570837974548),\n",
       " (u'moon', 0.9029580354690552),\n",
       " (u'orbit', 0.8970711827278137),\n",
       " (u'week', 0.8915328979492188),\n",
       " (u'reach', 0.8870389461517334)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(\"sun\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
